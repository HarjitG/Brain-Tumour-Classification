{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Notebook\n",
        "\n",
        "We start with the same 4 classes from the original notebook but convery the Tumor classes into 1 class, so now we only have Tumor vs Non Tumor"
      ],
      "metadata": {
        "id": "g8JArDd1of7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hxnSQqouwBT-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import imghdr\n",
        "#import optuna\n",
        "#import keras_tuner as kt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UI5-NKmOqcI9"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (256,256,3)\n",
        "OPT = tf.keras.optimizers.legacy.Adam(learning_rate = 0.001)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnOE0ERBdo8Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfOo5XUugp6f"
      },
      "outputs": [],
      "source": [
        "training_path = '/content/drive/MyDrive/projects/Brain_Tumor_Classification/Images_Brain/Training'\n",
        "testing_path = '/content/drive/MyDrive/projects/Brain_Tumor_Classification/Images_Brain/Testing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmiLYVp0weE0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaM2JIE8kt0l"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAGAWpF5lYQ6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmpWRPlG4IiN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZdOeDiD4ImB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWAWX9PGi83s"
      },
      "outputs": [],
      "source": [
        "# Load the training dataset\n",
        "Training_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    training_path,\n",
        "    labels='inferred',\n",
        "    image_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Load the validation dataset\n",
        "Validation_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    training_path,\n",
        "    labels='inferred',\n",
        "    image_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Load the testing dataset\n",
        "Testing_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    testing_path,\n",
        "    labels='inferred',\n",
        "    image_size=(256, 256),\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-60ZebtGeMU"
      },
      "outputs": [],
      "source": [
        "Training_iterator = Training_data.as_numpy_iterator()\n",
        "Testing_iterator = Testing_data.as_numpy_iterator()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMO48XKP3zYr"
      },
      "outputs": [],
      "source": [
        "batch_training = Training_iterator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnxqAAJ532Qr"
      },
      "outputs": [],
      "source": [
        "batch_training[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPqk0GqN35K9"
      },
      "outputs": [],
      "source": [
        "class_names = Training_data.class_names\n",
        "print(\"Class Names:\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANGddrsnNKjd"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
        "for idx, img_index in enumerate([12,13,14,15]):\n",
        "    ax[idx].imshow(batch_training[0][img_index].astype(int))\n",
        "    ax[idx].title.set_text(batch_training[1][img_index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvZB5_Zn4KcR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fldau65L4KZc"
      },
      "outputs": [],
      "source": [
        "# We are now dealing with just 2 lables, 0, 1, and 3 are tumor vs 2 which is non tumor\n",
        "\n",
        "\n",
        "\n",
        "def augment_image(x, y):\n",
        "\n",
        "    #  # Random left-right flip\n",
        "    # x = tf.image.random_flip_left_right(x)\n",
        "    # # Random up-down flip\n",
        "    # x = tf.image.random_flip_up_down(x)\n",
        "\n",
        "    #  # Random rotation (90-degree increments)\n",
        "    # num_rotations = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
        "    # x = tf.image.rot90(x, k=num_rotations)\n",
        "\n",
        "    # # Random zoom (zooming in or out)\n",
        "    # zoom_factor = tf.random.uniform(shape=[], minval=0.8, maxval=1.2)\n",
        "    # crop_size = tf.cast(tf.cast(tf.shape(x)[0:2], dtype=tf.float32) * zoom_factor, dtype=tf.int32)\n",
        "    # x = tf.image.central_crop(x, central_fraction=zoom_factor)\n",
        "    # x = tf.image.resize(x, crop_size)\n",
        "    # )\n",
        "    # Add more augmentation functions as needed\n",
        "    return x, y\n",
        "\n",
        "def get_positions(x, y): # Gets the position of the 1 so we can identify the type of tumor and then create the label\n",
        "    positions = tf.where(tf.equal(y, 1))\n",
        "    positions = tf.gather(positions[:, 1], tf.where(y == 1)[:, 0])\n",
        "    return x, positions\n",
        "\n",
        "def map_labels(x, y):\n",
        "    binary_labels = tf.where(tf.equal(y, 2), 0, 1)  # No tumor (2) becomes 0, others become 1\n",
        "    return x, binary_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imFLixu54KXF"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "num_classes = 4  # Adjust based on your number of classes\n",
        "\n",
        "\n",
        "# Load the training dataset\n",
        "Training_data = Training_data.map(augment_image)\n",
        "Training_data = Training_data.map(lambda x, y: (x / 255.0, tf.one_hot(y, num_classes)))\n",
        "Training_data = Training_data.map(get_positions)\n",
        "Training_data = Training_data.map(map_labels)\n",
        "\n",
        "\n",
        "# Load the validation dataset\n",
        "Validation_data = Validation_data.map(augment_image)\n",
        "Validation_data = Validation_data.map(lambda x, y: (x / 255.0, tf.one_hot(y, num_classes)))\n",
        "Validation_data = Validation_data.map(get_positions)\n",
        "Validation_data = Validation_data.map(map_labels)\n",
        "\n",
        "# Load the testing dataset\n",
        "Testing_data = Testing_data.map(augment_image)\n",
        "Testing_data = Testing_data.map(lambda x, y: (x / 255.0, tf.one_hot(y, num_classes)))\n",
        "Testing_data = Testing_data.map(get_positions)\n",
        "Testing_data = Testing_data.map(map_labels)\n",
        "\n",
        "# X is Images\n",
        "# Y is Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJppKGIQ4KSb"
      },
      "outputs": [],
      "source": [
        "batch_training = Training_data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDYixjfSsr1W"
      },
      "outputs": [],
      "source": [
        "batch_training[1] # We can see the labels are now all 0 and 1 to represent Tumor vs Non Tumor, which is what we wanted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd4YX8oxnSEI"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
        "for idx, img_index in enumerate([1,2,7,17]):\n",
        "    ax[idx].imshow(batch_training[0][img_index])\n",
        "    ax[idx].title.set_text(batch_training[1][img_index])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_class_names = ['No Tumor', 'Tumor']\n",
        "fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
        "for idx, img_index in enumerate([1,2,7,17]):\n",
        "    ax[idx].imshow(batch_training[0][img_index])\n",
        "    #ax[idx].title.set_text(batch_training[1][img_index])\n",
        "    ax[idx].title.set_text(new_class_names[batch_training[1][img_index]])"
      ],
      "metadata": {
        "id": "5jVvpiyFzAon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlWC7CJRqMe0"
      },
      "source": [
        "## Deep Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsYkQgS9qNCm"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# First have an input layer, going to have 16 filters, filter is a 3x3, stride of 1\n",
        "# Relu activation turns negative values to 0, and preserves positive values\n",
        "model.add(Conv2D(32, (3,3), 1, activation = 'relu', input_shape = IMAGE_SIZE))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(64, (3,3), 1, activation = 'relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), 1, activation = 'relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten()) # condense values\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation = 'relu', kernel_regularizer=l2(0.002)))\n",
        "# model.add(Dropout(rate=0.1))\n",
        "\n",
        "model.add(Dense(256, activation = 'relu', kernel_regularizer=l2(0.02)))\n",
        "#model.add(Dropout(rate=0.1))\n",
        "\n",
        "\n",
        "# Final layer that gives a single output and represets the label\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer= OPT, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fVXzrtfqU5a"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBBTq8YJq6KG"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97ej0ClPq65d"
      },
      "outputs": [],
      "source": [
        "logdir = '/content/drive/MyDrive/projects/Brain_Tumor_Classification/logs'\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBjbjYStq-F-"
      },
      "outputs": [],
      "source": [
        "hist = model.fit(Training_data, epochs = 15, validation_data = Validation_data, callbacks = [tensorboard_callback, early_stopping])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aduy4XtzrO4_"
      },
      "source": [
        "## Evaluation and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUcRXrjpxer_"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKa5i3Qvxeim"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF3-5sJKrQ8O"
      },
      "outputs": [],
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FmDBvEYzUXw"
      },
      "outputs": [],
      "source": [
        "labels_testing = []\n",
        "X_test =[]\n",
        "\n",
        "for batch in Testing_data.as_numpy_iterator():\n",
        "    x_test, y_test = batch\n",
        "    labels_testing.extend(y_test)\n",
        "    X_test.extend(x_test)\n",
        "\n",
        "labels_testing = np.array(labels_testing)\n",
        "X_test = np.array(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qT1OVVuAzlkk"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_ = labels_testing # Our true y values\n",
        "yhat_ =[] # Empty list for predicted variables\n",
        "\n",
        "yhat = model.predict(X_test)\n",
        "\n",
        "yhat_binary = np.argmax(yhat, axis=1)\n",
        "\n",
        "yhat_.append(yhat_binary)\n",
        "\n",
        "pre.update_state(y_, yhat_binary)\n",
        "re.update_state(y_, yhat_binary)\n",
        "acc.update_state(y_, yhat_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFjr1dWJzoYD"
      },
      "outputs": [],
      "source": [
        "print(f'Precision: {pre.result().numpy()}')\n",
        "print(f'Recall: {re.result().numpy()}')\n",
        "print(f'Accuracy: {acc.result().numpy()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U_Bvyoqzqtd"
      },
      "outputs": [],
      "source": [
        "class_names = [\"No Tumor\", \"Tumor\"]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf = confusion_matrix(y_, yhat_binary)\n",
        "\n",
        "sns.heatmap(conf, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4wuTN4ywujVNdU7tyha66"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}